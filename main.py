"""
Main script for the Local RAG Pipeline demonstration.
This script orchestrates the complete RAG pipeline workflow.
"""

import os
import json
from pathlib import Path
from datetime import datetime
from document_processor import DocumentProcessor
from llm_interface import LocalLLM, RAGPipeline
from rag_evaluator import evaluate_rag_pipeline


def main():
    """Main function to run the complete RAG pipeline demonstration."""
    
    print("üöÄ Starting Local RAG Pipeline Demonstration")
    print("=" * 60)
    
    # Configuration
    MODELS_DIR = "models"
    INDEX_PATH = "faiss_index"
    RESULTS_DIR = "results"
    
    # Create directories
    os.makedirs(MODELS_DIR, exist_ok=True)
    os.makedirs(RESULTS_DIR, exist_ok=True)
    
    # Step 1: Initialize Document Processor
    print("\nüìö Step 1: Initializing Document Processor")
    processor = DocumentProcessor()
    
    # Step 2: Download and process documents
    print("\nüì• Step 2: Downloading and Processing Documents")
    
    if os.path.exists(f"{INDEX_PATH}.index") and os.path.exists(f"{INDEX_PATH}_chunks.pkl"):
        print("Found existing index, loading...")
        processor.load_index(INDEX_PATH)
    else:
        print("No existing index found, creating new one...")
        
        # Download sample documents
        files = processor.download_sample_documents("data")
        
        if not files:
            print("‚ùå No documents downloaded. Cannot proceed.")
            return
        
        # Process documents into chunks
        chunks = processor.process_documents(files)
        print(f"‚úì Processed {len(files)} documents into {len(chunks)} chunks")
        
        # Create embeddings
        embeddings = processor.create_embeddings()
        print(f"‚úì Created embeddings with shape: {embeddings.shape}")
        
        # Build FAISS index
        index = processor.build_faiss_index()
        print(f"‚úì Built FAISS index with {index.ntotal} vectors")
        
        # Save index for future use
        processor.save_index(INDEX_PATH)
        print(f"‚úì Saved index to {INDEX_PATH}")
    
    # Step 3: Initialize Local LLM
    print("\nü§ñ Step 3: Initializing Local LLM")
    llm = LocalLLM(model_type="gpt4all")
    
    try:
        llm.load_model(MODELS_DIR)
        print("‚úì Local LLM loaded successfully")
    except Exception as e:
        print(f"‚ùå Error loading LLM: {e}")
        print("Please ensure you have enough disk space and a stable internet connection.")
        return
    
    # Step 4: Create RAG Pipeline
    print("\nüîó Step 4: Creating RAG Pipeline")
    rag = RAGPipeline(processor, llm)
    print("‚úì RAG pipeline created")
    
    # Step 5: Define Sample Queries
    print("\n‚ùì Step 5: Processing Sample Queries")
    
    sample_queries = [
        "What is artificial intelligence and how is it used today?",
        "Explain machine learning and its main types.",
        "What are the advantages of Python programming language?"
    ]
    
    print(f"Processing {len(sample_queries)} sample queries...")
    
    # Process queries and collect results
    results = []
    
    for i, query in enumerate(sample_queries, 1):
        print(f"\nüîç Query {i}: {query}")
        print("-" * 50)
        
        try:
            result = rag.query(
                question=query,
                k=3,  # Retrieve top 3 relevant chunks
                max_tokens=300,
                temperature=0.7
            )
            
            # Display results
            print(f"\nüìÑ Retrieved {result['num_retrieved']} relevant chunks:")
            for j, chunk in enumerate(result['retrieved_chunks'], 1):
                source_name = Path(chunk['source']).name
                score = chunk['similarity_score']
                text_preview = chunk['text'][:100] + "..." if len(chunk['text']) > 100 else chunk['text']
                print(f"  {j}. [{source_name}] Score: {score:.4f}")
                print(f"     {text_preview}\n")
            
            print(f"ü§ñ Generated Response:")
            print(f"{result['response']}\n")
            
            results.append(result)
            
        except Exception as e:
            print(f"‚ùå Error processing query: {e}")
            continue
    
    # Step 6: Evaluate Results
    print("\nüìä Step 6: Evaluating RAG Pipeline Performance")
    print("=" * 60)
    
    if results:
        try:
            # Save results to file
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            results_file = os.path.join(RESULTS_DIR, f"rag_results_{timestamp}.json")
            
            # Convert results to JSON-serializable format
            json_results = []
            for result in results:
                json_result = {
                    'question': result['question'],
                    'response': result['response'],
                    'num_retrieved': result['num_retrieved'],
                    'retrieved_chunks': [
                        {
                            'text': chunk['text'],
                            'source': chunk['source'],
                            'similarity_score': float(chunk['similarity_score']),
                            'chunk_id': chunk.get('chunk_id', ''),
                        }
                        for chunk in result['retrieved_chunks']
                    ]
                }
                json_results.append(json_result)
            
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(json_results, f, indent=2, ensure_ascii=False)
            
            print(f"‚úì Results saved to: {results_file}")
            
            # Perform evaluation
            evaluation_file = os.path.join(RESULTS_DIR, f"evaluation_report_{timestamp}.txt")
            evaluation = evaluate_rag_pipeline(results, evaluation_file)
            
            # Save evaluation metrics as JSON
            eval_json_file = os.path.join(RESULTS_DIR, f"evaluation_metrics_{timestamp}.json")
            with open(eval_json_file, 'w', encoding='utf-8') as f:
                json.dump(evaluation, f, indent=2, default=str)
            
            print(f"‚úì Evaluation metrics saved to: {eval_json_file}")
            
        except Exception as e:
            print(f"‚ùå Error during evaluation: {e}")
    
    # Step 7: Summary
    print("\nüéâ Pipeline Demonstration Complete!")
    print("=" * 60)
    print("\nWhat was accomplished:")
    print("‚úì Downloaded and processed public documents")
    print("‚úì Created semantic embeddings using sentence-transformers")
    print("‚úì Built FAISS vector index for efficient retrieval")
    print("‚úì Loaded and used a local LLM (GPT4All)")
    print("‚úì Implemented complete RAG pipeline")
    print("‚úì Processed 3 sample queries with retrieval and generation")
    print("‚úì Evaluated pipeline performance using multiple metrics")
    
    print(f"\nüìÅ Results and evaluations saved in: {RESULTS_DIR}/")
    print("\nNext steps:")
    print("‚Ä¢ Review the evaluation report for insights")
    print("‚Ä¢ Experiment with different queries")
    print("‚Ä¢ Try different embedding models or LLMs")
    print("‚Ä¢ Add more documents to improve knowledge coverage")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Process interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Unexpected error: {e}")
        print("Please check the error details above and try again.")
